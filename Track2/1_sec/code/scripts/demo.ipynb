{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECODER_NUM_WQ:     16285696\n",
      "DECODER_NUM_WS:     2035712\n",
      "DECODER_W_BYTES:    11705344\n",
      "CLS_NUM_WQ:         136134656\n",
      "CLS_NUM_WS:         17016832\n",
      "CLS_W_BYTES:        97846784\n",
      "DECODER_NUM_X:      7168\n",
      "DECODER_X_BITS:     229376\n",
      "DECODER_X_BYTES:    28672\n",
      "CLS_NUM_Y:          1215488\n",
      "CLS_Y_BITS:         38895616\n",
      "CLS_Y_BYTES:        4861952\n",
      "KV_CACHE_BYTES:     16515072\n",
      "EMBEDDING_BYTES:    272269312\n",
      "TOTAL_BYTES:        378775040\n",
      "ADDR_DECODER_X:    00000000375B0000\n",
      "ADDR_DECODER_Y:    00000000375B8000\n",
      "ADDR_CLS_Y:        0000000037D00000\n",
      "ADDR_DECODER_W:    0000000038200000\n",
      "ADDR_CLS_W:        0000000048E00000\n",
      "ADDR_KV_CACHE:     000000004EC00000\n"
     ]
    }
   ],
   "source": [
    "from fpga_qwen import *\n",
    "\n",
    "# print hyperparameters\n",
    "print(f\"DECODER_NUM_WQ:     {DECODER_NUM_WQ}\")\n",
    "print(f\"DECODER_NUM_WS:     {DECODER_NUM_WS}\")\n",
    "print(f\"DECODER_W_BYTES:    {DECODER_W_BYTES}\")\n",
    "print(f\"CLS_NUM_WQ:         {CLS_NUM_WQ}\")\n",
    "print(f\"CLS_NUM_WS:         {CLS_NUM_WS}\")\n",
    "print(f\"CLS_W_BYTES:        {CLS_W_BYTES}\")\n",
    "print(f\"DECODER_NUM_X:      {DECODER_NUM_X}\")\n",
    "print(f\"DECODER_X_BITS:     {DECODER_X_BITS}\")\n",
    "print(f\"DECODER_X_BYTES:    {DECODER_X_BYTES}\")\n",
    "print(f\"CLS_NUM_Y:          {CLS_NUM_Y}\")\n",
    "print(f\"CLS_Y_BITS:         {CLS_Y_BITS}\")\n",
    "print(f\"CLS_Y_BYTES:        {CLS_Y_BYTES}\")\n",
    "print(f\"KV_CACHE_BYTES:     {KV_CACHE_BYTES}\")\n",
    "print(f\"EMBEDDING_BYTES:    {EMBEDDING_BYTES}\")\n",
    "print(f\"TOTAL_BYTES:        {TOTAL_BYTES}\")\n",
    "\n",
    "# print the addresses with 64bit hex\n",
    "print(f\"ADDR_DECODER_X:    {ADDR_DECODER_X:016X}\")\n",
    "print(f\"ADDR_DECODER_Y:    {ADDR_DECODER_Y:016X}\")\n",
    "print(f\"ADDR_CLS_Y:        {ADDR_CLS_Y:016X}\")\n",
    "print(f\"ADDR_DECODER_W:    {ADDR_DECODER_W:016X}\")\n",
    "print(f\"ADDR_CLS_W:        {ADDR_CLS_W:016X}\")\n",
    "print(f\"ADDR_KV_CACHE:     {ADDR_KV_CACHE:016X}\")\n",
    "# reset kv cache to 0\n",
    "ddr_kv_cache[:] = 0\n",
    "\n",
    "# create qwen fpga accelerator\n",
    "accelerator = QWEN_ACCELERATOR(qwen, tokenizer, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_chat_template(prompt):\n",
    "    # compose the prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    tokens = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    # do generation\n",
    "    input_ids = tokenizer.encode(tokens, add_special_tokens=True)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "give the source code of  'quick sort' in c++ as short as possible, no comment.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "```cpp\n",
      "#include <iostream>\n",
      "#include <vector>\n",
      "\n",
      "void quickSort(std::vector<int>& arr, int low, int high) {\n",
      "    if (low < high) {\n",
      "        int pi = partition(arr, low, high);\n",
      "        quickSort(arr, low, pi - 1);\n",
      "        quickSort(arr, pi + 1, high);\n",
      "    }\n",
      "}\n",
      "\n",
      "int partition(std::vector<int>& arr, int low, int high) {\n",
      "    int pivot = arr[high];\n",
      "    int i = low - 1;\n",
      "    for (int j = low; j < high; j++) {\n",
      "        if (arr[j] < pivot) {\n",
      "            i++;\n",
      "            std::swap(arr[i],"
     ]
    }
   ],
   "source": [
    "\"\"\"A DEMO for in-time generation\"\"\"\n",
    "# prompt = \"To be, or not to be, that is the question. 这句话出自哪里？\"\n",
    "# prompt = \"Please introduce Peking University.\"\n",
    "# prompt = \"Complete the text: In the beginning God created the heavens and the earth. Now the earth was formless and empty, darkness was over the surface of the deep, and the Spirit of God was hovering over the waters.\" \n",
    "# prompt = \"give the source code of  'quick sort' in c++ as short as possible, no comment.\"\n",
    "# prompt = \"What is one plus one? You only need to give the answer.\"\n",
    "# prompt = \"1+1等于多少？\"\n",
    "prompt = \"How many tastes does oreo have?\"\n",
    "\n",
    "input_ids = apply_chat_template(prompt)\n",
    "for output_ids in accelerator.generate_iter(input_ids, include_prefill=True):\n",
    "    output_seq = tokenizer.decode(output_ids, skip_special_tokens=False)\n",
    "    print(output_seq, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "中国的首都是？<|im_end|>\n",
      "<|im_start|>assistant\n",
      "中国的首都是北京。<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"directly generate all output\"\"\"\n",
    "prompt = \"中国的首都是？\"\n",
    "# prompt = \"What is the capital of China?\"\n",
    "\n",
    "input_ids = apply_chat_template(prompt)\n",
    "output_ids = accelerator.generate(input_ids, include_prefill=True)\n",
    "output_seq = tokenizer.decode(output_ids, skip_special_tokens=False)\n",
    "print(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefill Throughput: 165.01 tok/s\n",
      "Prefill Throughput: 165.14 tok/s\n",
      "Prefill Throughput: 165.69 tok/s\n",
      "Prefill Throughput: 165.50 tok/s\n",
      "Prefill Throughput: 165.67 tok/s\n",
      "Prefill Throughput: 165.28 tok/s\n",
      "Prefill Throughput: 165.60 tok/s\n",
      "Prefill Throughput: 165.60 tok/s\n",
      "Prefill Throughput: 165.73 tok/s\n",
      "Prefill Throughput: 165.52 tok/s\n",
      "Decode Throughput: 9.44 tok/s\n",
      "Decode Throughput: 9.44 tok/s\n",
      "Decode Throughput: 9.40 tok/s\n",
      "Decode Throughput: 9.45 tok/s\n",
      "Decode Throughput: 9.41 tok/s\n",
      "Decode Throughput: 9.42 tok/s\n",
      "Decode Throughput: 9.39 tok/s\n",
      "Decode Throughput: 9.44 tok/s\n",
      "Decode Throughput: 9.41 tok/s\n",
      "Decode Throughput: 9.46 tok/s\n"
     ]
    }
   ],
   "source": [
    "# test throughput\n",
    "\n",
    "# Clocks.fclk0_mhz = 375\n",
    "\n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    accelerator.run_prefill(0)\n",
    "    end = time.time()\n",
    "    gen_throughput = 1/(end-start)\n",
    "    pre_throughput = gen_throughput * T\n",
    "    print(f\"Prefill Throughput: {pre_throughput:.2f} tok/s\")\n",
    "    \n",
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    accelerator.run_hardware(0)\n",
    "    end = time.time()\n",
    "    gen_throughput = 1/(end-start)\n",
    "    pre_throughput = gen_throughput * T\n",
    "    print(f\"Decode Throughput: {gen_throughput:.2f} tok/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
